{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Promblem a \n",
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "    for l in urlopen(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "    return feat\n",
    "\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data = data[:int(len(data)/3)]\n",
    "validation_data = data[int(len(data)/3):2*int(len(data)/3)]\n",
    "test_data = data[2*int(len(data)/3):]\n",
    "X_train = [feature(d) for d in train_data]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in train_data]\n",
    "X_validation = [feature(d) for d in validation_data]\n",
    "y_validation = [d['beer/ABV'] >= 6.5 for d in validation_data]\n",
    "X_test = [feature(d) for d in test_data]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in test_data]\n",
    "\n",
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= log(1 + exp(-logit))\n",
    "        if not y[i]:\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "    return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0]*len(theta)\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        for k in range(len(theta)):\n",
    "            dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "            if not y[i]:\n",
    "                dl[k] -= X[i][k]\n",
    "    for k in range(len(theta)):\n",
    "        dl[k] -= lam*2*theta[k]\n",
    "    return numpy.array([-x for x in dl])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(lam):\n",
    "    theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X_train[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(theta, X, y):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train lambda = 1.0:\taccuracy=0.717508700348014\n",
      "validation lambda = 1.0:\taccuracy=0.718408736349454\n",
      "test lambda = 1.0:\taccuracy=0.7215022798176146\n"
     ]
    }
   ],
   "source": [
    "#question 1\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta,X_train,y_train)\n",
    "print(\"train lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))\n",
    "\n",
    "\n",
    "acc = performance(theta,X_validation,y_validation)\n",
    "print(\"validation lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))\n",
    "\n",
    "acc = performance(theta,X_test,y_test)\n",
    "print(\"test lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 12340\n",
      "negetive 4328\n",
      "True_positive=  9105 True_negetive = 1407 False_positive =  3235 False_negetive =  2921\n"
     ]
    }
   ],
   "source": [
    "#question 2\n",
    "scores = [inner(theta,x) for x in X_test]\n",
    "predictions = [s > 0 for s in scores]\n",
    "correct = [(a==b) for (a,b) in zip(predictions,y_test)]\n",
    "print('positive',sum(predictions))\n",
    "print('negetive',len(predictions)-sum(predictions))\n",
    "True_positive =0\n",
    "True_negetive =0\n",
    "False_positive = 0\n",
    "False_negetive = 0\n",
    "i=0\n",
    "for i in range(len(predictions)) :\n",
    "    if predictions[i] == True:\n",
    "        if y_test[i] == True:\n",
    "            True_positive =True_positive +1\n",
    "            i=i+1\n",
    "        else:\n",
    "            False_positive =False_positive +1\n",
    "            i=i+1\n",
    "    elif y_test[i] == True:\n",
    "        True_negetive = True_negetive + 1\n",
    "        i=i+1\n",
    "    else:\n",
    "        False_negetive= False_negetive+1\n",
    "        i=i+1\n",
    "print('True_positive= ',True_positive,'True_negetive =',True_negetive,'False_positive = ',False_positive,'False_negetive = ',False_negetive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3 \n",
    "#To assign greater importance to False Positives compared to False Negatives,I need to change the def f.I will add two more judgements and make it into four situation TP,TN,NP,NN.\n",
    "#Then I apply 10 times weight for the FP situations(if not y[i] and x[i]>0 )\n",
    "#Finally,add two more judgements and change the coefficient of FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation lambda = 0:\taccuracy=0.718948757950318\n",
      "validation lambda = 0.01:\taccuracy=0.719188767550702\n",
      "validation lambda = 0.1:\taccuracy=0.718648745949838\n",
      "validation lambda = 1:\taccuracy=0.718408736349454\n",
      "validation lambda = 100:\taccuracy=0.6694467778711148\n"
     ]
    }
   ],
   "source": [
    "#question 4\n",
    "import numpy as np\n",
    "a= [0,0.01,0.1,1,100]\n",
    "array1=[]\n",
    "for lam in a:\n",
    "    theta = train(lam)\n",
    "    acc = performance(theta,X_validation,y_validation)\n",
    "    array1.append(acc)\n",
    "    print(\"validation lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda is  0.01\n",
      "train lambda = 0.01:\taccuracy=0.718288731549262\n",
      "validation lambda = 0.01:\taccuracy=0.719188767550702\n",
      "test lambda = 0.01:\taccuracy=0.7224022078233742\n"
     ]
    }
   ],
   "source": [
    "print('The best lambda is ',a[array1.index(max(array1))])\n",
    "lam = a[array1.index(max(array1))]\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta,X_train,y_train)\n",
    "print(\"train lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))\n",
    "\n",
    "\n",
    "acc = performance(theta,X_validation,y_validation)\n",
    "print(\"validation lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))\n",
    "\n",
    "acc = performance(theta,X_test,y_test)\n",
    "print(\"test lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
