{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "    for l in urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random data\n",
    "random.shuffle(data)\n",
    "\n",
    "## split\n",
    "training_data= data[:int(len(data)/3)]\n",
    "vali_data= data[int(len(data)/3):2*int(len(data)/3)]\n",
    "test_data= data[2*int(len(data)/3):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X_train = [feature(d) for d in training_data]\n",
    "y_train = [d['beer/ABV'] >= 6.5 for d in training_data]\n",
    "\n",
    "X_vali = [feature(d) for d in vali_data]\n",
    "y_vali = [d['beer/ABV'] >= 6.5 for d in vali_data]\n",
    "\n",
    "X_test = [feature(d) for d in test_data]\n",
    "y_test = [d['beer/ABV'] >= 6.5 for d in test_data]\n",
    "\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X_train[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy of train set=0.7170886835473419\n",
      "lambda = 1.0:\taccuracy of validation set=0.7157086283451338\n",
      "lambda = 1.0:\taccuracy of test set=0.7220422366210704\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta, X_train, y_train)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of train set=\" + str(acc))\n",
    "\n",
    "acc = performance(theta, X_vali, y_vali)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of validation set=\" + str(acc))\n",
    "\n",
    "acc = performance(theta, X_test, y_test)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of test set=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a=[True]\n",
    "if a[0] ==True :\n",
    "    print('1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
