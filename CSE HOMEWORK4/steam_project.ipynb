{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = []\n",
    "items_count_list =[]\n",
    "steam_id_list =[]\n",
    "url_list =[]\n",
    "items_list =[]\n",
    "for l in  readGz('australian_users_items.json.gz'):\n",
    "    user_id,items_count,steam_id,url,items = l['user_id'],l['items_count'],l['steam_id'],l['user_url'],l['items']\n",
    "    user_id_list.append(user_id)\n",
    "    items_count_list.append(items_count)\n",
    "    steam_id_list.append(steam_id)\n",
    "    url_list.append(url)\n",
    "    items_list.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_name= defaultdict(list)\n",
    "for l in range(len(items_list)):\n",
    "    for i in range(len(items_list[l])):\n",
    "        item_id,item_name = items_list[l][i]['item_id'],items_list[l][i]['item_name']\n",
    "        item_id_name[item_id].append(item_name)\n",
    "id_name_set ={}\n",
    "for l in item_id_name:\n",
    "    id_name_set[l] =set(item_id_name[l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "item_recommend = defaultdict(list)\n",
    "item_review = defaultdict(list)\n",
    "review_helpful =defaultdict(list)\n",
    "review_recommend = defaultdict(list)\n",
    "text = []\n",
    "data2 = list(readGz('australian_user_reviews.json.gz'))\n",
    "\n",
    "random.shuffle(data2)\n",
    "length = len(data2)\n",
    "review_train = data2[0:round(length*0.5)]\n",
    "review_validation =data2[round(length*0.5):round(length*0.8)]\n",
    "review_test  = data2 [round(length*0.8):]\n",
    "for l in  review_train:\n",
    "    review = l['reviews']\n",
    "    text.append(review)\n",
    "    for i in review:\n",
    "        funny,posted,item_id,helpful,recommend,review_text =i['funny'],i['posted'],i['item_id'],i['helpful'],i['recommend'],i['review']\n",
    "        review_recommend[review_text].append(recommend)\n",
    "        review_helpful[review_text].append(helpful)\n",
    "        item_review[item_id].append(review_text)\n",
    "        item_recommend[item_id].append(recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_list =[]\n",
    "for i in range(len(text)):\n",
    "    for l in text[i]:\n",
    "        review_list.append(l['review'])\n",
    "for i in review_recommend:\n",
    "    if len(review_recommend[i]) >1:\n",
    "        review_recommend[i]=review_recommend[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "punctuation = set(string.punctuation)\n",
    "old_w = ''\n",
    "cob=''\n",
    "wordCount = defaultdict(int)\n",
    "for l in review_recommend:\n",
    "    l =str(l)\n",
    "    r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_set =defaultdict(int)\n",
    "count = 0\n",
    "indicator = 0\n",
    "for i in words:\n",
    "    for j in review_recommend:\n",
    "        j = str(j)\n",
    "        if i in set(j.split()):\n",
    "            count+= 1\n",
    "    idf_set[i] = count\n",
    "    indicator+=1\n",
    "    count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n =len(review_recommend)\n",
    "for i in idf_set:\n",
    "    idf_set[i]=math.log10(n/(idf_set[i]+1))\n",
    "tf_set_r = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "                          \n",
    "for i in range(0,len(review_recommend)):\n",
    "    tf_set_r[i]=defaultdict(int)\n",
    "    for k in idf_set:\n",
    "        tf_set_r[i][k]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for k in review_recommend:\n",
    "    k = str(k)\n",
    "    r = ''.join([c for c in k.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        for j in idf_set:\n",
    "            if j == w:\n",
    "                tf_set_r[i][j]+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_r = defaultdict(int)\n",
    "for i in range(0,len(review_recommend)):\n",
    "    tf_idf_r[i] =[]\n",
    "for k in range(len(tf_set_r)):\n",
    "    for i in idf_set:\n",
    "        tf_idf_r[k].append(tf_set_r[k][i]*idf_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_list=[]\n",
    "for i in review_recommend:\n",
    "    recommend_list.append(review_recommend[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(recommend_list)):\n",
    "    if recommend_list[i] == [True]:\n",
    "        recommend_list[i] =True\n",
    "    elif recommend_list[i]==[False]:\n",
    "        recommend_list[i]= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list_train=[]\n",
    "new_list_train = []\n",
    "a= 0\n",
    "for i in range(len(tf_idf_r)):\n",
    "        temp_list_train.append(1)\n",
    "        for j in range(len(tf_idf_r[i])):\n",
    "            temp_list_train.append(tf_idf_r[i][j])\n",
    "        new_list_train.append(temp_list_train)\n",
    "        temp_list_train=[]\n",
    "X_train = new_list_train\n",
    "y_train = recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.07797986111547041\n",
      "0.1 0.07797986227201174\n",
      "1 0.07797996427670166\n",
      "10 0.07798428647535584\n",
      "100 0.07808515013399189\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regularization =[0.01,0.1,1,10,100]\n",
    "for k in regularization : \n",
    "    clf = linear_model.Ridge(k, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_train)\n",
    "    s= 0\n",
    "    for i in range(len(y_train)):\n",
    "        s +=(y_train[i]-predictions[i])**2\n",
    "    MSE = s/len(y_train)\n",
    "    print(k,MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_word ={}\n",
    "a = 0\n",
    "for i in range(1,1001):\n",
    "    dict_word[words[i-1]] = theta[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1 = [(dict_word[w], w) for w in dict_word]\n",
    "counts1.sort()\n",
    "counts1.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = list(readGz('australian_user_reviews.json.gz'))\n",
    "item_review_whole=defaultdict(list)\n",
    "for l in data3:\n",
    "    review = l['reviews']\n",
    "    for i in review:\n",
    "        item_id,review_text = i['item_id'],i['review']\n",
    "        item_review_whole[item_id].append(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_work = {}\n",
    "for i in item_review_whole:\n",
    "    item_work[i]=set()\n",
    "for i in item_review_whole:\n",
    "    for j in range(len(item_review_whole[i])):\n",
    "        l =str(item_review_whole[i][j])\n",
    "        r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "        for w in r.split():\n",
    "            item_work[i].add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_work_score = {}\n",
    "for i in item_work:\n",
    "    item_work_score[i]={}\n",
    "for i in item_work:\n",
    "    for j in item_work[i]:\n",
    "        if j in dict_word:\n",
    "            item_work_score[i][j]=dict_word[j]\n",
    "        else:\n",
    "            item_work_score[i][j]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_dict = {}\n",
    "for i in item_work_score:\n",
    "    sort_d = []\n",
    "    sort_d=sorted(item_work_score[i].items(),key = lambda d:d[1],reverse=True)\n",
    "    top5_dict[i]=sort_d[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    review_helpful_train= defaultdict(list)\n",
    "    review_helpful_test = defaultdict(list)\n",
    "    review_text = []\n",
    "    data4 = list(readGz('australian_user_reviews.json.gz'))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    a=[]\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    for l in  data4:\n",
    "        review= l['reviews']\n",
    "        for i in review:\n",
    "            helpful,review_important,item =i['helpful'],i['review'],i['item']\n",
    "            if helpful != 'No ratings yet':\n",
    "                k =str(helpful)\n",
    "                r = ''.join([c for c in k.lower() if not c in punctuation])\n",
    "                if int(a[2])>=5:\n",
    "                a= r.split()\n",
    "                review_helpful_train[review_important].append(helpful)\n",
    "            else:\n",
    "                review_helpful_test[review_important].append(helpful)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_helpful_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful_set_test =defaultdict(list)\n",
    "for i in review_helpful_test:\n",
    "    helpful_set_test[i].append(set(review_helpful_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful_set_train= defaultdict(list)\n",
    "helpful_set_validation= defaultdict(list)\n",
    "length =len(review_helpful_train)/2\n",
    "a = 0\n",
    "for i in review_helpful_train:\n",
    "    if a < length:\n",
    "        helpful_set_train[i].append(set(review_helpful_train[i]))\n",
    "    else:\n",
    "        helpful_set_validation[i].append(set(review_helpful_train[i]))\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "old_w = ''\n",
    "cob=''\n",
    "wordCount = defaultdict(int)\n",
    "for l in helpful_set_train:\n",
    "    l =str(l)\n",
    "    r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "        \n",
    "counts5 = [(wordCount[w], w) for w in wordCount]\n",
    "counts5.sort()\n",
    "counts5.reverse()\n",
    "words_helpful = [x[1] for x in counts5[:2000]]        \n",
    "        \n",
    "        \n",
    "idf_set_helpful =defaultdict(int)\n",
    "count = 0\n",
    "for i in words_helpful:\n",
    "    for j in helpful_set_train:\n",
    "        j = str(j)\n",
    "        if i in set(j.split()):\n",
    "            count+= 1\n",
    "    idf_set_helpful[i] = count\n",
    "    count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "idf_set_helpful_test =defaultdict(int)\n",
    "count = 0\n",
    "for i in words_helpful:\n",
    "    for j in helpful_set_test:\n",
    "        j = str(j)\n",
    "        if i in set(j.split()):\n",
    "            count+= 1\n",
    "    idf_set_helpful_test[i] = count\n",
    "    count=0\n",
    "n =len(helpful_set_test)\n",
    "for i in idf_set_helpful_test:\n",
    "    idf_set_helpful_test[i]=math.log10(n/(idf_set_helpful_test[i]+1))\n",
    "tf_set_r_helpful_test = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_test)):\n",
    "    tf_set_r_helpful_test[i]=defaultdict(int)\n",
    "    for k in idf_set_helpful_test:\n",
    "        tf_set_r_helpful_test[i][k]=0\n",
    "i=0\n",
    "for k in helpful_set_test:\n",
    "    k = str(k)\n",
    "    r = ''.join([c for c in k.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        for j in idf_set_helpful_test:\n",
    "            if j == w:\n",
    "                tf_set_r_helpful_test[i][j]+=1\n",
    "    i+=1\n",
    "tf_idf_r_helpful_test = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_test)):\n",
    "    tf_idf_r_helpful_test[i] =[]\n",
    "for k in range(len(tf_set_r_helpful_test)):\n",
    "    for i in idf_set_helpful_test:\n",
    "        tf_idf_r_helpful_test[k].append(tf_set_r_helpful_test[k][i]*idf_set_helpful_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_helpful_test = []\n",
    "a= 0\n",
    "for i in range(len(tf_idf_r_helpful_test)):\n",
    "        temp_helpful_test.append(1)\n",
    "        for j in range(len(tf_idf_r_helpful_test[i])):\n",
    "            temp_helpful_test.append(tf_idf_r_helpful_test[i][j])\n",
    "        new_helpful_test.append(temp_helpful_test)\n",
    "        temp_helpful_test=[]\n",
    "X_test = new_helpful_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n =len(helpful_set_train)\n",
    "for i in idf_set_helpful:\n",
    "    idf_set_helpful[i]=math.log10(n/(idf_set_helpful[i]+1))\n",
    "tf_set_r_helpful = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_train)):\n",
    "    tf_set_r_helpful[i]=defaultdict(int)\n",
    "    for k in idf_set_helpful:\n",
    "        tf_set_r_helpful[i][k]=0\n",
    "i=0\n",
    "for k in helpful_set_train:\n",
    "    k = str(k)\n",
    "    r = ''.join([c for c in k.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        for j in idf_set_helpful:\n",
    "            if j == w:\n",
    "                tf_set_r_helpful[i][j]+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_r_helpful = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_train)):\n",
    "    tf_idf_r_helpful[i] =[]\n",
    "for k in range(len(tf_set_r_helpful)):\n",
    "    for i in idf_set_helpful:\n",
    "        tf_idf_r_helpful[k].append(tf_set_r_helpful[k][i]*idf_set_helpful[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number =[]\n",
    "helpful_number =[]\n",
    "a = []\n",
    "for i in helpful_set_train:\n",
    "    if len(helpful_set_train[i])== 1:\n",
    "        l =str(helpful_set_train[i])\n",
    "        r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "        a= r.split()\n",
    "        helpful_number.append(a[0])\n",
    "        total_number.append(a[2])\n",
    "        a = []\n",
    "    else:\n",
    "        l =str(helpful_set_train[i][0])\n",
    "        r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "        a= r.split()\n",
    "        helpful_number.append(a[0])\n",
    "        total_number.append(a[2])\n",
    "        a = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful_rate_train =[]\n",
    "for i in range(len(helpful_number)):\n",
    "    helpful_rate_train.append((int(helpful_number[i]))/(int(total_number[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_helpful_train=[]\n",
    "new_helpful_train = []\n",
    "a= 0\n",
    "for i in range(len(tf_idf_r_helpful)):\n",
    "        temp_helpful_train.append(1)\n",
    "        for j in range(len(tf_idf_r_helpful[i])):\n",
    "            temp_helpful_train.append(tf_idf_r_helpful[i][j])\n",
    "        new_helpful_train.append(temp_helpful_train)\n",
    "        temp_helpful_train=[]\n",
    "X_train = new_helpful_train\n",
    "y_train = helpful_rate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "idf_set_helpful_validation =defaultdict(int)\n",
    "count = 0\n",
    "for i in words_helpful:\n",
    "    for j in helpful_set_validation:\n",
    "        j = str(j)\n",
    "        if i in set(j.split()):\n",
    "            count+= 1\n",
    "    idf_set_helpful_validation[i] = count\n",
    "    count=0\n",
    "n =len(helpful_set_validation)\n",
    "for i in idf_set_helpful_validation:\n",
    "    idf_set_helpful_validation[i]=math.log10(n/(idf_set_helpful_validation[i]+1))\n",
    "tf_set_r_helpful_validation = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_validation)):\n",
    "    tf_set_r_helpful_validation[i]=defaultdict(int)\n",
    "    for k in idf_set_helpful_validation:\n",
    "        tf_set_r_helpful_validation[i][k]=0\n",
    "i=0\n",
    "for k in helpful_set_validation:\n",
    "    k = str(k)\n",
    "    r = ''.join([c for c in k.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        for j in idf_set_helpful_validation:\n",
    "            if j == w:\n",
    "                tf_set_r_helpful_validation[i][j]+=1\n",
    "    i+=1\n",
    "tf_idf_r_helpful_validation = defaultdict(int)\n",
    "for i in range(0,len(helpful_set_validation)):\n",
    "    tf_idf_r_helpful_validation[i] =[]\n",
    "for k in range(len(tf_set_r_helpful_validation)):\n",
    "    for i in idf_set_helpful_validation:\n",
    "        tf_idf_r_helpful_validation[k].append(tf_set_r_helpful_validation[k][i]*idf_set_helpful_validation[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_validation =[]\n",
    "helpful_number_validation =[]\n",
    "a = []\n",
    "for i in helpful_set_validation:\n",
    "    if len(helpful_set_validation[i])== 1:\n",
    "        l =str(helpful_set_validation[i])\n",
    "        r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "        a= r.split()\n",
    "        helpful_number_validation.append(a[0])\n",
    "        total_number_validation.append(a[2])\n",
    "        a = []\n",
    "    else:\n",
    "        l =str(helpful_set_validation[i][0])\n",
    "        r = ''.join([c for c in l.lower() if not c in punctuation])\n",
    "        a= r.split()\n",
    "        helpful_number_validation.append(a[0])\n",
    "        total_number_validation.append(a[2])\n",
    "        a = []\n",
    "helpful_rate_validation =[]\n",
    "for i in range(len(helpful_number_validation)):\n",
    "    helpful_rate_validation.append((int(helpful_number_validation[i]))/(int(total_number_validation[i])))\n",
    "temp_helpful_validation=[]\n",
    "new_helpful_validation = []\n",
    "a= 0\n",
    "for i in range(len(tf_idf_r_helpful_validation)):\n",
    "        temp_helpful_validation.append(1)\n",
    "        for j in range(len(tf_idf_r_helpful_validation[i])):\n",
    "            temp_helpful_validation.append(tf_idf_r_helpful_validation[i][j])\n",
    "        new_helpful_validation.append(temp_helpful_validation)\n",
    "        temp_helpful_validation=[]\n",
    "X_validation = new_helpful_validation\n",
    "y_validation = helpful_rate_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.15291716986623757\n",
      "0.1 0.15109803502480085\n",
      "1 0.13755789403462637\n",
      "10 0.10316849183571665\n",
      "100 0.0764987379209909\n",
      "1000 0.0847630702969212\n",
      "10000 0.1773727099848295\n",
      "100000 0.2682069253875025\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regularization =[0.01,0.1,1,10,100,1000,10000,100000]\n",
    "for k in regularization:\n",
    "    clf = linear_model.Ridge(k, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_validation)\n",
    "    s= 0\n",
    "    for i in range(len(y_validation)):\n",
    "        if predictions[i]<0:\n",
    "            predictions[i]=0\n",
    "        elif predictions[i]>1:\n",
    "            predictions[i]=1\n",
    "        s +=(y_validation[i]-predictions[i])**2\n",
    "    MSE = s/len(y_validation)\n",
    "    print(k,MSE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = linear_model.Ridge(100, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "y1 = []\n",
    "for i in y_train:\n",
    "    if i>= 0.5:\n",
    "        y1.append(1)\n",
    "    else:\n",
    "        y1.append(0)\n",
    "\n",
    "\n",
    "vectorizer=TfidfVectorizer()\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y1)\n",
    "predictions=classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7208"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
