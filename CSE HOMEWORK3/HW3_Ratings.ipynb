{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish training set and validation set\n",
    "\n",
    "train_set = set()\n",
    "validation_set = set()\n",
    "count = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):    \n",
    "    count += 1\n",
    "    if count <= 100000:\n",
    "        train_set.add(l['reviewerID'] + '-' + l['itemID'])\n",
    "    else:\n",
    "        validation_set.add(l['reviewerID'] + '-' + l['itemID'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of alpha is 4.232\n"
     ]
    }
   ],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "count = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "    count += 1\n",
    "    if count == 100000:\n",
    "        break\n",
    "    \n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "\n",
    "print(\"The value of alpha is \" + str(globalAverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the ratings of the validation set\n",
    "allRatings = []\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    allRatings.append(l['rating'])\n",
    "\n",
    "validation_ratings = allRatings[100000:]\n",
    "len(validation_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the trivial predictor on the validation set is 1.222481119999121\n"
     ]
    }
   ],
   "source": [
    "# MSE on the validation set\n",
    "import numpy as np\n",
    "\n",
    "validation_ratings = np.array(validation_ratings)\n",
    "\n",
    "MSE = sum((validation_ratings-globalAverage)**2)/len(validation_ratings)\n",
    "\n",
    "print(\"The MSE of the trivial predictor on the validation set is \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "\n",
    "# construct a rating dictionary for the training set\n",
    "TR_dict = defaultdict(float)\n",
    "train_ratings = allRatings[0:100000]\n",
    "count = 0\n",
    "\n",
    "for l in train_set:\n",
    "    TR_dict[l] = train_ratings[count]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct initial beta_u and beta_i dictionary\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "lamda = 1\n",
    "alpha = globalAverage\n",
    "\n",
    "# construct user_ratings dictionary and item_ratings dictionary\n",
    "UR_dict = defaultdict(list)\n",
    "IR_dict = defaultdict(list)\n",
    "\n",
    "for key in TR_dict:\n",
    "    UR_dict[key.split('-')[0]].append(TR_dict[key])\n",
    "    IR_dict[key.split('-')[1]].append(TR_dict[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct user_average dictionary and item_average dictionary\n",
    "UA_dict = defaultdict(float)\n",
    "IA_dict = defaultdict(float)\n",
    "\n",
    "for key in UR_dict:\n",
    "    UA_dict[key] = sum(UR_dict[key])/len(UR_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in IR_dict:\n",
    "    IA_dict[key] = sum(IR_dict[key])/len(IR_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-81.75614914973565"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize beta_u and beta_i\n",
    "for key in UA_dict:\n",
    "    beta_u[key] = UA_dict[key] - alpha\n",
    "\n",
    "for key in IA_dict:\n",
    "    beta_i[key] = IA_dict[key] - alpha\n",
    "k =0\n",
    "for i in beta_i:\n",
    "    k+= beta_i[i]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate the procedure until convergence\n",
    "# First of all, we have to construct user-item and item-user dictionaries\n",
    "UI_dict = defaultdict(list)\n",
    "IU_dict = defaultdict(list)\n",
    "\n",
    "for l in train_set:\n",
    "    UI_dict[l.split('-')[0]].append(l.split('-')[1])\n",
    "    IU_dict[l.split('-')[1]].append(l.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36427"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_u_new = beta_u.copy()\n",
    "beta_i_new = beta_i.copy()\n",
    "UR_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-46.62368735521407\n",
      "-46.623687355215395\n"
     ]
    }
   ],
   "source": [
    "# iteration\n",
    "alpha_new = alpha\n",
    "lamda = 1\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    # update alpha\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "    for key in TR_dict:\n",
    "        sum_1 += TR_dict[key]\n",
    "    for key in beta_u_new:\n",
    "        sum_2 += beta_u_new[key]\n",
    "    for key in beta_i_new:\n",
    "        sum_3 += beta_i_new[key]\n",
    "    alpha_new = (sum_1 - sum_2 -sum_3)/len(train_set)\n",
    "    print(sum_2)\n",
    "    print(sum_3)\n",
    "    # update beta_u\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "\n",
    "    for key in beta_u_new:\n",
    "        count_item = []\n",
    "        sum_1 = sum(UR_dict[key])\n",
    "        sum_2 = alpha_new*len(UR_dict[key])\n",
    "        for item in UI_dict[key]:\n",
    "            count_item.append(item)\n",
    "        for x in count_item:\n",
    "            sum_3 += beta_i_new[x]\n",
    "        beta_u_new[key] = (sum_1 - sum_2 -sum_3)/(lamda + len(UI_dict[key]))\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        sum_3 = 0\n",
    "\n",
    "    # update beta_i\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "\n",
    "    for key in beta_i_new:\n",
    "        count_user = []\n",
    "        sum_1 = sum(IR_dict[key])\n",
    "        sum_2 = alpha_new*len(IR_dict[key])\n",
    "        for user in IU_dict[key]:\n",
    "            count_user.append(user)\n",
    "        for x in count_user:\n",
    "            sum_3 += beta_u_new[x]\n",
    "        beta_i_new[key] = (sum_1 - sum_2 - sum_3)/(lamda + len(IU_dict[key]))\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        sum_3 = 0       \n",
    "    # calculate MSE on the validation set\n",
    "    rating_prediction = []\n",
    "    validation_user = []\n",
    "    validation_item = []\n",
    "\n",
    "    for l in validation_set:\n",
    "        validation_user.append(l.split('-')[0])\n",
    "        validation_item.append(l.split('-')[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "The MSE on the validation set is 1.5909165487246155\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(validation_user)):\n",
    "    if validation_user[i] in beta_u_new and validation_item[i] in beta_i_new:\n",
    "        prediction = alpha_new + beta_u_new[validation_user[i]] + beta_i_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    elif validation_user[i] not in beta_u_new and validation_item[i] in beta_i_new:\n",
    "        prediction = alpha_new + beta_i_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    elif validation_user[i] in beta_u_new and validation_item[i] not in beta_i_new:\n",
    "        prediction = alpha_new + beta_u_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    else:\n",
    "        prediction = alpha_new\n",
    "        rating_prediction.append(prediction)\n",
    "\n",
    "rating_prediction = np.array(rating_prediction)\n",
    "print(len(rating_prediction))\n",
    "validation_MSE = sum((rating_prediction - validation_ratings)**2)/len(rating_prediction)\n",
    "print(\"The MSE on the validation set is \" + str(validation_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user with the largest value of beta is U157710283\n",
      "The item with the largest value of beta is I531372057\n",
      "The user with the smallest value of beta is U691931970\n",
      "The item with the smallest value of beta is I902264614\n"
     ]
    }
   ],
   "source": [
    "# Question 7\n",
    "max_user = []\n",
    "max_item = []\n",
    "min_user = []\n",
    "min_item = []\n",
    "\n",
    "for key in beta_u_new:\n",
    "    max_user.append(beta_u_new[key])\n",
    "max_user_beta = max(max_user)\n",
    "max_user_ID = [k for k,v in beta_u_new.items() if v == max_user_beta][0]\n",
    "print(\"The user with the largest value of beta is \" + str(max_user_ID))\n",
    "\n",
    "for key in beta_i_new:\n",
    "    max_item.append(beta_i_new[key])\n",
    "max_item_beta = max(max_item)\n",
    "max_item_ID = [k for k,v in beta_i_new.items() if v == max_item_beta][0]\n",
    "print(\"The item with the largest value of beta is \" + str(max_item_ID))\n",
    "\n",
    "for key in beta_u_new:\n",
    "    min_user.append(beta_u_new[key])\n",
    "min_user_beta = min(min_user)\n",
    "min_user_ID = [k for k,v in beta_u_new.items() if v == min_user_beta][0]\n",
    "print(\"The user with the smallest value of beta is \" + str(min_user_ID))\n",
    "\n",
    "for key in beta_i_new:\n",
    "    min_item.append(beta_i_new[key])\n",
    "min_item_beta = min(min_item)\n",
    "min_item_ID = [k for k,v in beta_i_new.items() if v == min_item_beta][0]\n",
    "print(\"The item with the smallest value of beta is \" + str(min_item_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the validation set is 1.2240486232479748\n"
     ]
    }
   ],
   "source": [
    "# Question 8\n",
    "\n",
    "# After several trials, we discovered that when lamda equals 100, the MSE on the validation set \n",
    "# is smallest.\n",
    "\n",
    "# iteration\n",
    "alpha_new = alpha\n",
    "lamda = 100\n",
    "beta_u_new = beta_u.copy()\n",
    "beta_i_new = beta_i.copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # update alpha\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "    for key in TR_dict:\n",
    "        sum_1 += TR_dict[key]\n",
    "    for key in beta_u_new:\n",
    "        sum_2 += beta_u_new[key]\n",
    "    for key in beta_i_new:\n",
    "        sum_3 += beta_i_new[key]\n",
    "    alpha_new = (sum_1 - sum_2 -sum_3)/len(train_set)\n",
    "\n",
    "    # update beta_u\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "\n",
    "    for key in beta_u_new:\n",
    "        count_item = []\n",
    "        sum_1 = sum(UR_dict[key])\n",
    "        sum_2 = alpha_new*len(UR_dict[key])\n",
    "        for item in UI_dict[key]:\n",
    "            count_item.append(item)\n",
    "        for x in count_item:\n",
    "            sum_3 += beta_i_new[x]\n",
    "        beta_u_new[key] = (sum_1 - sum_2 -sum_3)/(lamda + len(UI_dict[key]))\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        sum_3 = 0\n",
    "\n",
    "    # update beta_i\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    sum_3 = 0\n",
    "\n",
    "    for key in beta_i_new:\n",
    "        count_user = []\n",
    "        sum_1 = sum(IR_dict[key])\n",
    "        sum_2 = alpha_new*len(IR_dict[key])\n",
    "        for user in IU_dict[key]:\n",
    "            count_user.append(user)\n",
    "        for x in count_user:\n",
    "            sum_3 += beta_u_new[x]\n",
    "        beta_i_new[key] = (sum_1 - sum_2 - sum_3)/(lamda + len(IU_dict[key]))\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        sum_3 = 0 \n",
    "        \n",
    "# calculate MSE on the validation set\n",
    "rating_prediction = []\n",
    "validation_user = []\n",
    "validation_item = []\n",
    "\n",
    "for l in validation_set:\n",
    "    validation_user.append(l.split('-')[0])\n",
    "    validation_item.append(l.split('-')[1])\n",
    "\n",
    "for i in range(len(validation_user)):\n",
    "    if validation_user[i] in beta_u_new and validation_item[i] in beta_i_new:\n",
    "        prediction = alpha_new + beta_u_new[validation_user[i]] + beta_i_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    elif validation_user[i] not in beta_u_new and validation_item[i] in beta_i_new:\n",
    "        prediction = alpha_new + beta_i_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    elif validation_user[i] in beta_u_new and validation_item[i] not in beta_i_new:\n",
    "        prediction = alpha_new + beta_u_new[validation_item[i]]\n",
    "        rating_prediction.append(prediction)\n",
    "    else:\n",
    "        prediction = alpha_new\n",
    "        rating_prediction.append(prediction)\n",
    "\n",
    "rating_prediction = np.array(rating_prediction)\n",
    "\n",
    "validation_MSE = sum((rating_prediction - validation_ratings)**2)/len(rating_prediction)\n",
    "print(\"The MSE on the validation set is \" + str(validation_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the test set\n",
    "\n",
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if u in beta_u_new and i in beta_i_new:\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha_new + beta_u_new[u] + beta_i_new[i]) + '\\n')\n",
    "    elif u not in beta_u_new and i in beta_i_new:\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha_new + beta_i_new[i]) + '\\n')\n",
    "    elif u in beta_u_new and i not in beta_i_new:\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha_new + beta_u_new[i]) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha_new) + '\\n')\n",
    "          \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
