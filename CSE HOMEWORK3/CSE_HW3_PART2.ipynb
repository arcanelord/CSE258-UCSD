{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "    \n",
    "businessCount = defaultdict(int)\n",
    "userinformation = defaultdict(list)\n",
    "userinformation_train = defaultdict(list)\n",
    "iteminformation_train = defaultdict(list)\n",
    "userinformation_train_raw = defaultdict(list)\n",
    "iteminformation_train_raw = defaultdict(list)\n",
    "userinformation_validation = defaultdict(list)\n",
    "userrating_train = []\n",
    "iteminformation =defaultdict(list)\n",
    "UR =defaultdict(list)\n",
    "userrating_validation = []\n",
    "userrating_validation_check = defaultdict(list)\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "train_set =set()\n",
    "validation_set =set()\n",
    "count = 0\n",
    "all_set = set()\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    userinformation[user].append(item)\n",
    "    iteminformation[item].append(user)\n",
    "    allRatings.append(l['rating'])\n",
    "    all_set.add(l['reviewerID'] + '-' + l['itemID'])\n",
    "    if count < 100000:\n",
    "        user,business = l['reviewerID'],l['itemID']\n",
    "        userinformation_train[user].append(l['rating'])\n",
    "        iteminformation_train[item].append(l['rating'])\n",
    "        train_set.add(l['reviewerID'] + '-' + l['itemID'])\n",
    "        userinformation_train_raw[user].append(l['rating'])\n",
    "        iteminformation_train_raw[item].append(l['rating'])\n",
    "        userrating_train.append(l['rating'])\n",
    "        count = count +1 \n",
    "    else:\n",
    "        user,business = l['reviewerID'],l['itemID']\n",
    "        userinformation_validation[user].append(l['rating'])\n",
    "        userrating_validation.append(l['rating'])\n",
    "        validation_set.add(l['reviewerID'] + '-' + l['itemID'])\n",
    "        userrating_validation_check[user].append(l['rating'])\n",
    "        count = count +1 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.23471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.23471"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgrating_train = sum(userrating_train)/len(userrating_train)\n",
    "avgrating_all = sum(allRatings)/len(allRatings)\n",
    "print(avgrating_all)\n",
    "4.23471\n",
    "\n",
    "#so the avgrating_train ,what is alpha is 4.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.222481119999121"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s= 0\n",
    "for i in range(0,len(userrating_validation)):\n",
    "    s +=(userrating_validation[i]-avgrating_train)**2\n",
    "MSE = s/len(userrating_validation)\n",
    "MSE\n",
    "#MSE is 1.22248 if using average to predict validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 6\n",
    "TR_dict = defaultdict(float)\n",
    "UR_dict = defaultdict(list)\n",
    "IR_dict = defaultdict(list)\n",
    "count = 0\n",
    "dict1 =defaultdict(list)\n",
    "dict2 =defaultdict(list)\n",
    "for l in all_set:\n",
    "    TR_dict[l] = allRatings[count]\n",
    "    count += 1\n",
    "for i in TR_dict:\n",
    "    UR_dict[i.split('-')[0]].append(TR_dict[i])\n",
    "    IR_dict[i.split('-')[1]].append(TR_dict[i])\n",
    "for USER in UR_dict:\n",
    "    dict1[USER] = sum(UR_dict[USER])/len(UR_dict[USER])\n",
    "for ITEM in IR_dict:\n",
    "    dict2[ITEM] = sum(IR_dict[ITEM])/len(IR_dict[ITEM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = avgrating_all\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "for item in IR_dict:\n",
    "    beta_i[item] = dict2[item] -alpha\n",
    "for user in UR_dict:\n",
    "    beta_u[user] = dict1[user] -alpha    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UI_dict = defaultdict(list)\n",
    "IU_dict = defaultdict(list)\n",
    "\n",
    "for l in train_set:\n",
    "    UI_dict[l.split('-')[0]].append(l.split('-')[1])\n",
    "    IU_dict[l.split('-')[1]].append(l.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converge(value, value_last, epsilon):\n",
    "    error = 0\n",
    "    for i in value:\n",
    "        error += abs(value[i] - value_last[i])\n",
    "    #print error\n",
    "    if error < epsilon:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "validation_data = []\n",
    "index = 0\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if index < 100000:\n",
    "        train_data.append(l)\n",
    "    else:\n",
    "        train_data.append(l)\n",
    "        validation_data.append(l)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8006089303641547 False\n",
      "0.7924273075042008 False\n",
      "0.7921697776735136 False\n",
      "0.7921175263533872 False\n",
      "0.7921022512217537 False\n",
      "0.792097531707272 False\n",
      "0.7920960405384493 False\n",
      "0.7920955626170733 False\n",
      "0.7920954109848238 False\n",
      "0.7920953672876619 False\n",
      "0.7920953597495424 False\n",
      "0.7920953638243952 False\n",
      "0.7920953708499832 False\n",
      "0.7920953777870913 False\n",
      "0.792095383681045 False\n",
      "0.7920953883637308 False\n",
      "0.7920953919498037 False\n",
      "0.7920953946348827 False\n",
      "0.792095396615821 False\n",
      "0.7920953980624932 False\n",
      "0.7920953991114749 False\n",
      "0.79209539986819 False\n",
      "0.7920954004120448 False\n",
      "0.7920954008018274 False\n",
      "0.7920954010806364 False\n",
      "0.792095401279755 False\n",
      "0.7920954014218206 False\n",
      "0.7920954015230705 False\n",
      "0.7920954015952197 False\n",
      "0.7920954016465687 False\n",
      "0.7920954016831279 False\n",
      "0.7920954017091482 False\n",
      "0.7920954017276427 False\n",
      "0.7920954017408107 False\n",
      "0.7920954017501934 False\n",
      "0.7920954017568456 False\n",
      "0.7920954017615875 False\n",
      "0.7920954017649586 True\n"
     ]
    }
   ],
   "source": [
    "    alpha = avgrating_train\n",
    "    beta_u = defaultdict(float)\n",
    "    beta_i = defaultdict(float)\n",
    "    for item in IR_dict:\n",
    "        beta_i[item] = dict2[item] -alpha\n",
    "    for user in UR_dict:\n",
    "        beta_u[user] = dict1[user] -alpha         \n",
    "    lamda = 5\n",
    "    count = 0\n",
    "    epsilon =0.0001\n",
    "    finish = False\n",
    "    s=0\n",
    "    MSE_old = 3\n",
    "    alpha_new =alpha\n",
    "    beta_u_new = beta_u.copy()\n",
    "    beta_i_new = beta_i.copy()\n",
    "    while count ==0 :\n",
    "        num_train = len(train_data)\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            alpha_new += (l[\"rating\"] - beta_u[user] - \\\n",
    "                          beta_i[item])\n",
    "        alpha_new /= num_train\n",
    "        num_item = defaultdict(int)\n",
    "        for user in beta_u_new:\n",
    "            beta_u_new[user] = 0\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            num_item[user] += 1\n",
    "            beta_u_new[user] += (l[\"rating\"] - alpha_new - beta_i[item])\n",
    "        for user in beta_u:\n",
    "            beta_u_new[user] /= (lamda + num_item[user])\n",
    "        num_user = defaultdict(int)\n",
    "        for item in beta_i_new:\n",
    "            beta_i_new[item] = 0\n",
    "        for l in train_data:\n",
    "            user,item = l['reviewerID'],l['itemID']\n",
    "            num_user[item] += 1\n",
    "            beta_i_new[item] += (l[\"rating\"] - alpha_new - beta_u_new[user])\n",
    "        for item in beta_i_new:\n",
    "            beta_i_new[item] /= (lamda + num_user[item])\n",
    "        \n",
    "        if abs(alpha - alpha_new) < epsilon and \\\n",
    "        converge(beta_u, beta_u_new, epsilon)\\\n",
    "        and converge(beta_i, beta_i_new, epsilon):\n",
    "            finish = True\n",
    "        beta_u = beta_u_new.copy()\n",
    "        beta_i = beta_i_new.copy()\n",
    "        prediction = []\n",
    "        alpha = alpha_new\n",
    "        for l in validation_data:\n",
    "            user,item,rating = l['reviewerID'],l['itemID'],l['rating']\n",
    "            if user in beta_u_new:\n",
    "                user_judgement = True\n",
    "            else:\n",
    "                user_judgement = False\n",
    "            if item in beta_i_new:\n",
    "                item_judgement = True\n",
    "            else:\n",
    "                item_judgement = False\n",
    "            if item_judgement == False and user_judgement == False :\n",
    "                predict_value = alpha_new\n",
    "            elif item_judgement == False and user_judgement == True:\n",
    "                predict_value = alpha_new + beta_u_new[user]\n",
    "            elif item_judgement == True and user_judgement ==False:\n",
    "                predict_value = alpha_new + beta_i_new[item]\n",
    "            else:\n",
    "                predict_value = alpha_new + beta_i_new[item]+beta_u_new[user]\n",
    "            s += (predict_value-rating)**2\n",
    "            predict_value = 0\n",
    "        MSE_new = s/len(validation_data)\n",
    "        s = 0\n",
    "        if MSE_new > MSE_old:\n",
    "            finish == True\n",
    "        MSE_old =MSE_new\n",
    "        print(MSE_new,finish)\n",
    "        if finish == True:\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min MSE is  0.7920954017649586\n",
      " iteration time is  0\n"
     ]
    }
   ],
   "source": [
    "# question MSE_old is 1.5667\n",
    "print ('Min MSE is ',MSE_new)\n",
    "count= count -1\n",
    "print(' iteration time is ',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = open(\"pairs_Rating.txt\",\"r\").readlines()\n",
    "test = test[1:]\n",
    "test = [i.strip() for i in test]\n",
    "prediction = []\n",
    "point = 0\n",
    "\n",
    "for i in test:\n",
    "    user,item = i.strip().split('-')\n",
    "    if user in beta_u_new:\n",
    "        user_judgement = True\n",
    "    else:\n",
    "        user_judgement = False\n",
    "    if item in beta_i_new:\n",
    "        item_judgement = True\n",
    "    else:\n",
    "        item_judgement = False\n",
    "    if item_judgement == False and user_judgement == False :\n",
    "        predict_value = alpha_new\n",
    "    elif item_judgement == False and user_judgement == True:\n",
    "        predict_value = alpha_new + beta_u_new[user]\n",
    "    elif item_judgement == True and user_judgement ==False:\n",
    "        predict_value = alpha_new + beta_i_new[item]\n",
    "    else:\n",
    "        predict_value = alpha_new + beta_i_new[item]+beta_u_new[user]\n",
    "    prediction.append(predict_value)\n",
    "    predict_value = 0\n",
    "import csv\n",
    "\n",
    "with open('prediction_rate.csv', 'w') as csv_file:\n",
    "    csv_write = csv.writer(csv_file)\n",
    "    for a in prediction:\n",
    "        csv_write.writerow(str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 7\n",
    "\n",
    "for c in range(0,1000):\n",
    "    beta_u_new = beta_u.copy()\n",
    "    beta_i_new = beta_i.copy()\n",
    "    lamda = 1*c\n",
    "    alpha = 4.232\n",
    "    beta_u_new = beta_u.copy()\n",
    "    beta_i_new = beta_i.copy()\n",
    "    alpha = 4.23471\n",
    "    l = 0\n",
    "    m = 0\n",
    "    n = 0\n",
    "while count > 0 :\n",
    "    for number in TR_dict:\n",
    "        l += TR_dict[number]\n",
    "    for user in beta_u:\n",
    "        m = beta_u_new[user] + m\n",
    "    for item in beta_i:\n",
    "        n += beta_i_new[item]\n",
    "    alpha_new = (l-m-n)/200000\n",
    "    l = 0\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for user in beta_u_new:\n",
    "        count_item = []\n",
    "        l = sum(UR_dict[user])\n",
    "        m = alpha_new*len(UR_dict[user])\n",
    "        for item in UI_dict[user]:\n",
    "            count_item.append(item)\n",
    "        for x in count_item:\n",
    "            n += beta_i_new[x]\n",
    "        beta_u_new[user] = (l - m -n)/(lamda + len(UI_dict[user]))\n",
    "        l = 0\n",
    "        m = 0\n",
    "        n = 0\n",
    "    for k in beta_i_new:\n",
    "        count_user = []\n",
    "        l = sum(IR_dict[k])\n",
    "        m = alpha_new*len(IR_dict[k])\n",
    "        for user in IU_dict[k]:\n",
    "            count_user.append(user)\n",
    "        for x in count_user:\n",
    "            n += beta_u_new[x]\n",
    "        beta_i_new[k] = (l - m -n)/(lamda + len(IU_dict[k]))\n",
    "        l = 0\n",
    "        m = 0\n",
    "        n = 0  \n",
    "    prediction = []\n",
    "    for i in range(0,len(validation_user)):\n",
    "        if validation_user[i] in beta_u_new:\n",
    "            user_judgement = True\n",
    "        else:\n",
    "            user_judgement = False\n",
    "        if validation_item[i] in beta_i_new:\n",
    "            item_judgement = True\n",
    "        else:\n",
    "            item_judgement = False\n",
    "        if item_judgement == False and user_judgement == False :\n",
    "            predict_value = alpha_new\n",
    "        elif item_judgement == False and user_judgement == True:\n",
    "            predict_value = alpha_new + beta_u_new[validation_user[i]]\n",
    "        elif item_judgement == True and user_judgement ==False:\n",
    "            predict_value = alpha_new + beta_i_new[validation_item[i]]\n",
    "        else:\n",
    "            predict_value = alpha_new + beta_i_new[validation_item[i]]+beta_u_new[validation_user[i]]\n",
    "        prediction.append(predict_value)\n",
    "        predict_value = 0\n",
    "    s= 0\n",
    "    for i in range(0,len(prediction)):\n",
    "        s +=(prediction[i]-userrating_validation[i])**2\n",
    "    MSE_new = s/len(prediction)\n",
    "    count = count -1\n",
    "    print(MSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has largest beta is  U606968682\n",
      "The user has smallest beta is  U916648954\n",
      "The item has largest beta is  I562830918\n",
      "The item has smallest beta is  I284886896\n"
     ]
    }
   ],
   "source": [
    "max_user = max(beta_u_new,key=beta_u_new.get)\n",
    "min_user = min(beta_u_new,key=beta_u_new.get)\n",
    "max_item = max(beta_i_new,key=beta_i_new.get)\n",
    "min_item = min(beta_i_new,key=beta_i_new.get)\n",
    "print('The user has largest beta is ',max_user)\n",
    "print('The user has smallest beta is ',min_user)\n",
    "print('The item has largest beta is ',max_item)\n",
    "print('The item has smallest beta is ',min_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_user = []\n",
    "validation_item = []\n",
    "for d in validation_set:\n",
    "        validation_user.append(d.split('-')[0])\n",
    "        validation_item.append(d.split('-')[1])\n",
    "MSE_list ={}\n",
    "#Question 8\n",
    "for c in range(0,1000):\n",
    "    beta_u_new = beta_u.copy()\n",
    "    beta_i_new = beta_i.copy()\n",
    "    lamda = 1*c\n",
    "    alpha = 4.232\n",
    "    l = 0\n",
    "    m = 0\n",
    "    n = 0\n",
    "    MSE_old = 3\n",
    "    MSE_new= 2\n",
    "    while MSE_new < MSE_old:\n",
    "        MSE_old = MSE_new\n",
    "        for number in TR_dict:\n",
    "            l += TR_dict[number]\n",
    "        for user in beta_u:\n",
    "            m = beta_u_new[user] + m\n",
    "        for item in beta_i:\n",
    "            n += beta_i_new[item]\n",
    "        alpha_new = (l-m-n)/100000\n",
    "        l = 0\n",
    "        m = 0\n",
    "        n = 0\n",
    "        for user in beta_u_new:\n",
    "            count_item = []\n",
    "            l = sum(UR_dict[user])\n",
    "            m = alpha_new*len(UR_dict[user])\n",
    "            for item in UI_dict[user]:\n",
    "                count_item.append(item)\n",
    "            for x in count_item:\n",
    "                n += beta_i_new[x]\n",
    "            beta_u_new[user] = (l - m -n)/(lamda + len(UI_dict[user]))\n",
    "            l = 0\n",
    "            m = 0\n",
    "            n = 0\n",
    "        for k in beta_i_new:\n",
    "            count_user = []\n",
    "            l = sum(IR_dict[k])\n",
    "            m = alpha_new*len(IR_dict[k])\n",
    "            for user in IU_dict[k]:\n",
    "                count_user.append(user)\n",
    "            for x in count_user:\n",
    "                n += beta_u_new[x]\n",
    "            beta_i_new[k] = (l - m -n)/(lamda + len(IU_dict[k]))\n",
    "            l = 0\n",
    "            m = 0\n",
    "            n = 0  \n",
    "        prediction = []\n",
    "        for i in range(0,len(validation_user)):\n",
    "            if validation_user[i] in beta_u_new:\n",
    "                user_judgement = True\n",
    "            else:\n",
    "                user_judgement = False\n",
    "            if validation_item[i] in beta_i_new:\n",
    "                item_judgement = True\n",
    "            else:\n",
    "                item_judgement = False\n",
    "            if item_judgement == False and user_judgement == False :\n",
    "                predict_value = alpha_new\n",
    "            elif item_judgement == False and user_judgement == True:\n",
    "                predict_value = alpha_new + beta_u_new[validation_user[i]]\n",
    "            elif item_judgement == True and user_judgement ==False:\n",
    "                predict_value = alpha_new + beta_i_new[validation_item[i]]\n",
    "            else:\n",
    "                predict_value = alpha_new + beta_i_new[validation_item[i]]+beta_u_new[validation_user[i]]\n",
    "            prediction.append(predict_value)\n",
    "            predict_value = 0\n",
    "        s= 0\n",
    "        for i in range(0,len(prediction)):\n",
    "            s +=(prediction[i]-userrating_validation[i])**2\n",
    "        MSE_new = s/len(prediction)\n",
    "    MSE_list[lamda]=MSE_old\n",
    "    print(lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5427342694902821\n",
      "1.555892053069471\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 8\n",
    "beta_u_new = beta_u.copy()\n",
    "beta_i_new = beta_i.copy()\n",
    "lamda= 4.5\n",
    "alpha = 4.23471\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "MSE_old = 3\n",
    "MSE_new= 2\n",
    "validation_user = []\n",
    "validation_item = []\n",
    "count = 0\n",
    "for d in validation_set:\n",
    "        validation_user.append(d.split('-')[0])\n",
    "        validation_item.append(d.split('-')[1])\n",
    "while MSE_new < MSE_old:\n",
    "    MSE_old = MSE_new\n",
    "    for number in TR_dict:\n",
    "        l += TR_dict[number]\n",
    "    for user in beta_u:\n",
    "        m = beta_u_new[user] + m\n",
    "    for item in beta_i:\n",
    "        n += beta_i_new[item]\n",
    "    alpha_new = (l-m-n)/200000\n",
    "    l = 0\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for user in beta_u_new:\n",
    "        count_item = []\n",
    "        l = sum(UR_dict[user])\n",
    "        m = alpha_new*len(UR_dict[user])\n",
    "        for item in UI_dict[user]:\n",
    "            count_item.append(item)\n",
    "        for x in count_item:\n",
    "            n += beta_i_new[x]\n",
    "        beta_u_new[user] = (l - m -n)/(lamda + len(UI_dict[user]))\n",
    "        l = 0\n",
    "        m = 0\n",
    "        n = 0\n",
    "    for k in beta_i_new:\n",
    "        count_user = []\n",
    "        l = sum(IR_dict[k])\n",
    "        m = alpha_new*len(IR_dict[k])\n",
    "        for user in IU_dict[k]:\n",
    "            count_user.append(user)\n",
    "        for x in count_user:\n",
    "            n += beta_u_new[x]\n",
    "        beta_i_new[k] = (l - m -n)/(lamda + len(IU_dict[k]))\n",
    "        l = 0\n",
    "        m = 0\n",
    "        n = 0  \n",
    "    prediction = []\n",
    "    for i in range(0,len(validation_user)):\n",
    "        if validation_user[i] in beta_u_new:\n",
    "            user_judgement = True\n",
    "        else:\n",
    "            user_judgement = False\n",
    "        if validation_item[i] in beta_i_new:\n",
    "            item_judgement = True\n",
    "        else:\n",
    "            item_judgement = False\n",
    "        if item_judgement == False and user_judgement == False :\n",
    "            predict_value = alpha_new\n",
    "        elif item_judgement == False and user_judgement == True:\n",
    "            predict_value = alpha_new + beta_u_new[validation_user[i]]\n",
    "        elif item_judgement == True and user_judgement ==False:\n",
    "            predict_value = alpha_new + beta_i_new[validation_item[i]]\n",
    "        else:\n",
    "            predict_value = alpha_new + beta_i_new[validation_item[i]]+beta_u_new[validation_user[i]]\n",
    "        prediction.append(predict_value)\n",
    "        predict_value = 0\n",
    "    s= 0\n",
    "    for i in range(0,len(prediction)):\n",
    "        s +=(prediction[i]-userrating_validation[i])**2\n",
    "    MSE_new = s/len(prediction)\n",
    "    count += 1\n",
    "    print(MSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
